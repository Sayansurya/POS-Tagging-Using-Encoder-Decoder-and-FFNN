{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from model import Seq2SeqPOSTagger\n",
    "from model2 import Encoder \n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = pickle.load(open('../data/index_to_tag.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('../word_vectors/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = pickle.load(open('../word_vectors/unknown_words.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_wv(word, rand=True): # generate word vectors \n",
    "    global word2vec, unknown_words\n",
    "    word = word.lower()\n",
    "    try:\n",
    "        word_vec = torch.tensor(word2vec[word]).reshape(1,-1) \n",
    "        return word_vec\n",
    "    except: # not in word2vec\n",
    "        try:\n",
    "            if word in unknown_words.keys(): # if in unknown words\n",
    "                word_vec = unknown_words[word].clone().detach().reshape(1,-1)\n",
    "                return word_vec\n",
    "            else:\n",
    "                if re.search(\"'\", word):\n",
    "                    word = re.split(\"'\", word)[0] # words with apostrophe are queried by removing apostrophe \n",
    "                    word_vec = torch.tensor(word2vec[word]).reshape(1,-1) \n",
    "                    return word_vec\n",
    "                if re.search('-', word): # for compound words, word vector of each word is averaged \n",
    "                    word_vec = torch.randn((1,300)) if rand else torch.zeros((1,300))\n",
    "                    words = re.split('-', word)\n",
    "                    for w in words:\n",
    "                        try:\n",
    "                            word_vec += word2vec[w]\n",
    "                        except:\n",
    "                            if w in unknown_words.keys():\n",
    "                                word_vec += unknown_words[w]                            \n",
    "                    word_vec = word_vec/len(words)\n",
    "                    return word_vec\n",
    "                else:\n",
    "                    if word not in unknown_words.keys():\n",
    "                        word_vec = torch.randn((1,300)) if rand else torch.zeros((1,300))\n",
    "                    else:\n",
    "                        word_vec = unknown_words[word]\n",
    "                    return word_vec\n",
    "        except:\n",
    "            if word not in unknown_words.keys():\n",
    "                word_vec = torch.randn((1,300)) if rand else torch.zeros((1,300))\n",
    "            else:\n",
    "                word_vec = unknown_words[word]\n",
    "            return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(300, 128, 1, 12)\n",
    "encoder_decoder = Seq2SeqPOSTagger(\n",
    "    encoder_input_dim=300,\n",
    "    decoder_input_dim=268,\n",
    "    output_dim=12,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder.load_state_dict(torch.load('runs/epochs=5,batch_size=128,hidden_dim=128,timestamp=2023-03-09_21-31-24/final_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('runs/enc_only,epochs=5,batch_size=128,hidden_dim=128,timestamp=2023-03-10_01-27-26/final_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'can the can-opener open the can ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vector = []\n",
    "for word in sentence.split():\n",
    "    print(word)\n",
    "    word_vec = gen_wv(word)\n",
    "    sentence_vector.append(word_vec)\n",
    "\n",
    "sentence_vector = torch.cat(sentence_vector).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    enc_output = model(sentence_vector.to('cuda'))\n",
    "    enc_output = softmax(enc_output.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    enc_dec_output = encoder_decoder.predict(sentence_vector.to('cuda'))\n",
    "    enc_dec_output = softmax(enc_dec_output.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tags = []\n",
    "for i in torch.argmax(enc_output, dim=1).tolist():\n",
    "    enc_tags.append(index2tag[i])\n",
    "enc_dec_tags = []\n",
    "for i in torch.argmax(enc_dec_output, dim=1).tolist():\n",
    "    enc_dec_tags.append(index2tag[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sentence.split()\n",
    "for i in range(len(words)):\n",
    "    print(words[i], \"\\t\", enc_tags[i], \"\\t\", enc_dec_tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
